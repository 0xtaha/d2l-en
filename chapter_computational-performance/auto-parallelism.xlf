<?xml version='1.0' encoding='UTF-8'?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file original="chapter_computational-performance/auto-parallelism.md" source-language="zh-CN" target-language="en-US" datatype="markdown">
    <header>
      <skl>
        <external-file href="chapter_computational-performance/auto-parallelism.skl.md"/>
      </skl>
    </header>
    <body>
      <trans-unit id="1">
        <source xml:lang="zh-CN">自动并行计算</source>
        <target xml:lang="en-US">Automatic Parallel Computation</target>
      </trans-unit>
      <trans-unit id="2">
        <source xml:lang="zh-CN">MXNet后端会自动构建计算图。通过计算图，系统可以知道所有计算的依赖关系，并可以选择将没有依赖关系的多个任务并行执行来获得计算性能的提升。例如<bpt id="l2">[</bpt>“异步计算”<ept id="l2">]</ept><bpt id="l3">(</bpt>async-computation.md<ept id="l3">)</ept>一节的第一个例子里依次执行了<bpt id="4">`</bpt>a = nd.ones((1, 2))<ept id="4">`</ept>和<bpt id="6">`</bpt>b = nd.ones((1, 2))<ept id="6">`</ept>。这两步计算之间并没有依赖关系，因此系统可以选择并行执行它们。</source>
        <target xml:lang="en-US">MXNet automatically constructs computational graphs at the back end. Using a computational graph, the system is aware of all the computational dependencies, and can selectively execute multiple non-interdependent tasks in parallel to improve computing performance. For instance, the first example in the <bpt id="l2">[</bpt>“Asynchronous Computation”<ept id="l2">]</ept><bpt id="l3">(</bpt>async-computation.md<ept id="l3">)</ept> section executes <bpt id="4">`</bpt>a = nd.ones((1, 2))<ept id="4">`</ept> and <bpt id="6">`</bpt>b = nd.ones((1, 2))<ept id="6">`</ept> in turn. There is no dependency between these two steps, so the system can choose to execute them in parallel.</target>
      </trans-unit>
      <trans-unit id="3">
        <source xml:lang="zh-CN">通常，一个运算符会用到所有CPU或单个GPU上全部的计算资源。例如，<bpt id="2">`</bpt>dot<ept id="2">`</ept>操作符会用到所有CPU（即使是一台机器上有多个CPU处理器）或单个GPU上所有的线程。如果每个操作符的计算量足够大，只在CPU上或者单个GPU上并行运行多个运算符时，每个运算符的运行只分到CPU或单个GPU上部分计算资源。即使这些计算可以并行，最终计算性能的提升可能并不明显。本节中探讨的自动并行计算主要关注同时使用CPU和GPU的并行计算，以及计算和通讯的并行。</source>
        <target xml:lang="en-US">Typically, a single operator will use all the computational resources on all CPUs or a single GPU. For example, the <bpt id="2">`</bpt>dot<ept id="2">`</ept> operator will use all threads on all CPUs (even if there are multiple CPU processors on a single machine) or a single GPU. If computational load of each operator is large enough and multiple operators are run in parallel on only on the CPU or a single GPU, then the operations of each operator can only receive a portion of computational resources of CPU or single GPU. Even if these computations can be parallelized, the ultimate increase in computing performance may not be significant. In this section, our discussion of automatic parallel computation mainly focuses on parallel computation using both CPUs and GPUs, as well as the parallelization of computation and communication.</target>
      </trans-unit>
      <trans-unit id="4">
        <source xml:lang="zh-CN">首先导入本节中实验所需的包或模块。注意，我们需要至少一个GPU才能运行本节实验。</source>
        <target xml:lang="en-US">First, import the required packages or modules for experiment in this section. Note that we need at least one GPU to run the experiment in this section.</target>
      </trans-unit>
      <trans-unit id="5">
        <source xml:lang="zh-CN">CPU和GPU的并行计算</source>
        <target xml:lang="en-US">Parallel Computation using CPUs and GPUs</target>
      </trans-unit>
      <trans-unit id="6">
        <source xml:lang="zh-CN">我们先介绍CPU和GPU的并行计算，例如程序中的计算既发生在CPU上，又发生在GPU上。先定义<bpt id="2">`</bpt>run<ept id="2">`</ept>函数，令它做10次矩阵乘法。</source>
        <target xml:lang="en-US">First, we will discuss parallel computation using CPUs and GPUs, for example, when computation in a program occurs both on the CPU and a GPU. First, define the <bpt id="2">`</bpt>run<ept id="2">`</ept> function so that it performs 10 matrix multiplications.</target>
      </trans-unit>
      <trans-unit id="7">
        <source xml:lang="zh-CN">接下来，分别在CPU和GPU上创建NDArray。</source>
        <target xml:lang="en-US">Next, create an NDArray on both the CPU and GPU.</target>
      </trans-unit>
      <trans-unit id="8">
        <source xml:lang="zh-CN">然后，分别使用它们在CPU和GPU上运行<bpt id="2">`</bpt>run<ept id="2">`</ept>函数并打印所需时间。</source>
        <target xml:lang="en-US">Then, use the two NDArrays to run the <bpt id="2">`</bpt>run<ept id="2">`</ept> function on both the CPU and GPU and print the time required.</target>
      </trans-unit>
      <trans-unit id="9">
        <source xml:lang="zh-CN">预热开始。</source>
        <target xml:lang="en-US">Warm-up begins.</target>
      </trans-unit>
      <trans-unit id="10">
        <source xml:lang="zh-CN">预热结束。</source>
        <target xml:lang="en-US">Warm-up ends.</target>
      </trans-unit>
      <trans-unit id="11">
        <source xml:lang="zh-CN">我们去掉<bpt id="2">`</bpt>run(x_cpu)<ept id="2">`</ept>和<bpt id="4">`</bpt>run(x_gpu)<ept id="4">`</ept>两个计算任务之间的<bpt id="6">`</bpt>nd.waitall()<ept id="6">`</ept>，希望系统能自动并行这两个任务。</source>
        <target xml:lang="en-US">We remove <bpt id="6">`</bpt>nd.waitall()<ept id="6">`</ept> between the two computing tasks <bpt id="2">`</bpt>run(x_cpu)<ept id="2">`</ept> and <bpt id="4">`</bpt>run(x_gpu)<ept id="4">`</ept> and hope the system can automatically parallel these two tasks.</target>
      </trans-unit>
      <trans-unit id="12">
        <source xml:lang="zh-CN">可以看到，当两个计算任务一起执行时，执行总时间小于它们分开执行的总和。这表示，MXNet能有效地在CPU和GPU上自动并行计算。</source>
        <target xml:lang="en-US">As we can see, when two computing tasks are executed together, the total execution time is less than the sum of their separate execution times. This means that MXNet can effectively automate parallel computation on CPUs and GPUs.</target>
      </trans-unit>
      <trans-unit id="13">
        <source xml:lang="zh-CN">计算和通讯的并行计算</source>
        <target xml:lang="en-US">Parallel Computation of Computing and Communication</target>
      </trans-unit>
      <trans-unit id="14">
        <source xml:lang="zh-CN">在同时使用CPU和GPU的计算中，我们经常需要在CPU和GPU之间复制数据，造成数据的通讯。在下面例子中，我们在GPU上计算，然后将结果复制回CPU。我们分别打印GPU上计算时间和GPU到CPU的通讯时间。</source>
        <target xml:lang="en-US">In computations that use both the CPU and GPU, we often need to copy data between the CPU and GPU, resulting in data communication. In the example below, we compute on the GPU and then copy the results back to the CPU. We print the GPU computation time and the communication time from the GPU to CPU.</target>
      </trans-unit>
      <trans-unit id="15">
        <source xml:lang="zh-CN">我们去掉计算和通讯之间的<bpt id="2">`</bpt>waitall<ept id="2">`</ept>函数，打印这两个任务完成的总时间。</source>
        <target xml:lang="en-US">We remove the <bpt id="2">`</bpt>waitall<ept id="2">`</ept> function between computation and communication and print the total time need to complete both tasks.</target>
      </trans-unit>
      <trans-unit id="16">
        <source xml:lang="zh-CN">可以看到，执行计算和通讯的总时间小于两者分别执行的耗时之和。需要注意的是，这个计算并通讯的任务不同于本节之前介绍的同时使用CPU和GPU并行计算的任务。这里的运行和通讯之间有依赖关系：<bpt id="2">`</bpt>y[i]<ept id="2">`</ept>必须先计算好才能复制到CPU。所幸的是，在计算<bpt id="4">`</bpt>y[i]<ept id="4">`</ept>的时候系统可以复制<bpt id="6">`</bpt>y[i-1]<ept id="6">`</ept>，从而减少计算和通讯的总运行时间。</source>
        <target xml:lang="en-US">As we can see, the total time required to perform computation and communication is less than the sum of their separate execution times. It should be noted that this computation and communication task is different from the parallel computation task that simultaneously used the CPU and GPU described earlier in this section. Here, there is a dependency between execution and communication: <bpt id="2">`</bpt>y[i]<ept id="2">`</ept> must be computed before it can be copied to the CPU. Fortunately, the system can copy <bpt id="6">`</bpt>y[i-1]<ept id="6">`</ept> when computing <bpt id="4">`</bpt>y[i]<ept id="4">`</ept> to reduce the total running time of computation and communication.</target>
      </trans-unit>
      <trans-unit id="17">
        <source xml:lang="zh-CN">小结</source>
        <target xml:lang="en-US">Summary</target>
      </trans-unit>
      <trans-unit id="18">
        <source xml:lang="zh-CN">MXNet能够通过自动并行计算提升计算性能，例如CPU和GPU的并行计算以及计算和通讯的并行。</source>
        <target xml:lang="en-US">MXNet can improve computing performance through automatic parallel computation, such as parallel computation using the CPU and GPU and the parallelization of computation and communication.</target>
      </trans-unit>
      <trans-unit id="19">
        <source xml:lang="zh-CN">练习</source>
        <target xml:lang="en-US">exercise</target>
      </trans-unit>
      <trans-unit id="20">
        <source xml:lang="zh-CN">本节中定义的<bpt id="2">`</bpt>run<ept id="2">`</ept>函数里做了10次运算。它们之间也没有依赖关系。设计实验，看看MXNet有没有自动并行执行它们。</source>
        <target xml:lang="en-US">10 operations were performed in the <bpt id="2">`</bpt>run<ept id="2">`</ept> function defined in this section. There are no dependencies between them. Design an experiment to see if MXNet will automatically execute them in parallel.</target>
      </trans-unit>
      <trans-unit id="21">
        <source xml:lang="zh-CN">设计包含更加复杂的数据依赖的计算任务，通过实验观察MXNet能否得到正确结果并提升计算性能。</source>
        <target xml:lang="en-US">Designing computation tasks that include more complex data dependencies, and run experiments to see if MXNet can obtain the correct results and improve computing performance.</target>
      </trans-unit>
      <trans-unit id="22">
        <source xml:lang="zh-CN">当运算符的计算量足够小时，仅在CPU或单GPU上并行计算也可能提升计算性能。设计实验来验证这一点。</source>
        <target xml:lang="en-US">When the computational load of an operator is small enough, parallel computation on only the CPU or a single GPU may also improve the computing performance. Design an experiment to verify this.</target>
      </trans-unit>
      <trans-unit id="23">
        <source xml:lang="zh-CN">扫码直达<bpt id="l2">[</bpt>讨论区<ept id="l2">]</ept><bpt id="l3">(</bpt>https://discuss.gluon.ai/t/topic/1883<ept id="l3">)</ept></source>
        <target xml:lang="en-US">Scan the QR Code to Access <bpt id="l2">[</bpt>Discussions<ept id="l2">]</ept><bpt id="l3">(</bpt>https://discuss.gluon.ai/t/topic/1883<ept id="l3">)</ept></target>
      </trans-unit>
      <trans-unit id="24">
        <source xml:lang="zh-CN"><bpt id="1">![</bpt>../img/qr_auto-parallelism.svg<ept id="1">]</ept></source>
        <target xml:lang="en-US"><bpt id="1">![</bpt>../img/qr_auto-parallelism.svg<ept id="1">]</ept></target>
      </trans-unit>
    </body>
 </file>
</xliff>