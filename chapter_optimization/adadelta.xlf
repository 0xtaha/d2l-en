<?xml version='1.0' encoding='UTF-8'?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" version="1.2">
  <file original="chapter_optimization/adadelta.md" source-language="zh-CN" target-language="en-US" datatype="markdown">
    <header>
      <skl>
        <external-file href="chapter_optimization/adadelta.skl.md"/>
      </skl>
    </header>
    <body>
      <trans-unit id="1">
        <source xml:lang="zh-CN">Adadelta</source>
        <target xml:lang="en-US">Adadelta</target>
      </trans-unit>
      <trans-unit id="2">
        <source xml:lang="zh-CN">除了RMSProp以外，另一个常用优化算法Adadelta也针对Adagrad在迭代后期可能较难找到有用解的问题做了改进 <bpt id="2">[</bpt>1<ept id="2">]</ept>。有意思的是，Adadelta没有学习率这一超参数。</source>
        <target xml:lang="en-US">In addition to RMSProp, Adadelta is another common optimization algorithm that helps improve the chances of finding useful solutions at later stages of iteration, which is difficult to do when using the Adagrad algorithm for the same purpose<bpt id="2">[</bpt>1<ept id="2">]</ept>. The interesting thing is that there is no learning rate hyperparameter in the Adadelta algorithm.</target>
      </trans-unit>
      <trans-unit id="3">
        <source xml:lang="zh-CN">算法</source>
        <target xml:lang="en-US">The Algorithm</target>
      </trans-unit>
      <trans-unit id="4">
        <source xml:lang="zh-CN">Adadelta算法也像RMSProp一样，使用了小批量随机梯度$\boldsymbol{g}_t$按元素平方的指数加权移动平均变量$\boldsymbol{s}_t$。在时间步0，它的所有元素被初始化为0。
给定超参数$0 \leq \rho %%%less-than%%% 1$（对应RMSProp中的$\gamma$），在时间步$t&gt;0$，同RMSProp一样计算</source>
        <target xml:lang="en-US">Like RMSProp, the Adadelta algorithm uses the variable $\boldsymbol{s}_t$, which is an EWMA on the squares of elements in mini-batch stochastic gradient $\boldsymbol{g}_t$. At time step 0, all the elements are initialized to 0.
Given the hyperparameter $0 \leq \rho %%%less-than%%% 1$ (counterpart of $\gamma$ in RMSProp), at time step $t&gt;0$, compute using the same method as RMSProp:</target>
      </trans-unit>
      <trans-unit id="5">
        <source xml:lang="zh-CN">$$\boldsymbol{s}<bpt id="3">_</bpt>t \leftarrow \rho \boldsymbol{s}<ept id="3">_</ept>{t-1} + (1 - \rho) \boldsymbol{g}_t \odot \boldsymbol{g}_t.</source>
        <target xml:lang="en-US">$$\boldsymbol{s}<bpt id="3">_</bpt>t \leftarrow \rho \boldsymbol{s}<ept id="3">_</ept>{t-1} + (1 - \rho) \boldsymbol{g}_t \odot \boldsymbol{g}_t.</target>
      </trans-unit>
      <trans-unit id="6">
        <source xml:lang="zh-CN">$$</source>
        <target xml:lang="en-US">$$</target>
      </trans-unit>
      <trans-unit id="7">
        <source xml:lang="zh-CN">与RMSProp不同的是，Adadelta还维护一个额外的状态变量$\Delta\boldsymbol{x}<bpt id="4">_</bpt>t$，其元素同样在时间步0时被初始化为0。我们使用$\Delta\boldsymbol{x}<ept id="4">_</ept>{t-1}$来计算自变量的变化量：</source>
        <target xml:lang="en-US">Unlike RMSProp, Adadelta maintains an additional state variable, $\Delta\boldsymbol{x}<bpt id="4">_</bpt>t$ the elements of which are also initialized to 0 at time step 0. We use $\Delta\boldsymbol{x}<ept id="4">_</ept>{t-1}$ to compute the variation of the independent variable:</target>
      </trans-unit>
      <trans-unit id="8">
        <source xml:lang="zh-CN">$$ \boldsymbol{g}<bpt id="3">_</bpt>t' \leftarrow \sqrt{\frac{\Delta\boldsymbol{x}<ept id="3">_</ept>{t-1} + \epsilon}{\boldsymbol{s}_t + \epsilon}}   \odot \boldsymbol{g}_t, $$</source>
        <target xml:lang="en-US">$$ \boldsymbol{g}<bpt id="3">_</bpt>t' \leftarrow \sqrt{\frac{\Delta\boldsymbol{x}<ept id="3">_</ept>{t-1} + \epsilon}{\boldsymbol{s}_t + \epsilon}}   \odot \boldsymbol{g}_t, $$</target>
      </trans-unit>
      <trans-unit id="9">
        <source xml:lang="zh-CN">其中$\epsilon$是为了维持数值稳定性而添加的常数，例如$10^{-5}$。接着更新自变量：</source>
        <target xml:lang="en-US">Here, $\epsilon$ is a constant added to maintain the numerical stability, such as $10^{-5}$. Next, we update the independent variable:</target>
      </trans-unit>
      <trans-unit id="10">
        <source xml:lang="zh-CN">$$\boldsymbol{x}<bpt id="3">_</bpt>t \leftarrow \boldsymbol{x}<ept id="3">_</ept>{t-1} - \boldsymbol{g}'_t.</source>
        <target xml:lang="en-US">$$\boldsymbol{x}<bpt id="3">_</bpt>t \leftarrow \boldsymbol{x}<ept id="3">_</ept>{t-1} - \boldsymbol{g}'_t.</target>
      </trans-unit>
      <trans-unit id="11">
        <source xml:lang="zh-CN">$$</source>
        <target xml:lang="en-US">$$</target>
      </trans-unit>
      <trans-unit id="12">
        <source xml:lang="zh-CN">最后，我们使用$\Delta\boldsymbol{x}$来记录自变量变化量$\boldsymbol{g}'$按元素平方的指数加权移动平均：</source>
        <target xml:lang="en-US">Finally, we use $\Delta\boldsymbol{x}$ to record the EWMA on the squares of elements in $\boldsymbol{g}'$, which is the variation of the independent variable.</target>
      </trans-unit>
      <trans-unit id="13">
        <source xml:lang="zh-CN">$$\Delta\boldsymbol{x}<bpt id="4">_</bpt>t \leftarrow \rho \Delta\boldsymbol{x}<ept id="4">_</ept>{t-1} + (1 - \rho) \boldsymbol{g}'_t \odot \boldsymbol{g}'_t.</source>
        <target xml:lang="en-US">$$\Delta\boldsymbol{x}<bpt id="4">_</bpt>t \leftarrow \rho \Delta\boldsymbol{x}<ept id="4">_</ept>{t-1} + (1 - \rho) \boldsymbol{g}'_t \odot \boldsymbol{g}'_t.</target>
      </trans-unit>
      <trans-unit id="14">
        <source xml:lang="zh-CN">$$</source>
        <target xml:lang="en-US">$$</target>
      </trans-unit>
      <trans-unit id="15">
        <source xml:lang="zh-CN">可以看到，如不考虑$\epsilon$的影响，Adadelta跟RMSProp不同之处在于使用$\sqrt{\Delta\boldsymbol{x}_{t-1}}$来替代超参数$\eta$。</source>
        <target xml:lang="en-US">As we can see, if the impact of $\epsilon$ is not considered here, Adadelta differs from RMSProp in its replacement of the hyperparameter $\eta$ with $\sqrt{\Delta\boldsymbol{x}_{t-1}}$.</target>
      </trans-unit>
      <trans-unit id="16">
        <source xml:lang="zh-CN">从零开始实现</source>
        <target xml:lang="en-US">Implementation from Scratch</target>
      </trans-unit>
      <trans-unit id="17">
        <source xml:lang="zh-CN">Adadelta需要对每个自变量维护两个状态变量，$\boldsymbol{s}_t$和$\Delta\boldsymbol{x}_t$。我们按算法中的公式实现Adadelta。</source>
        <target xml:lang="en-US">Adadelta needs to maintain two state variables for each independent variable, $\boldsymbol{s}_t$ and $\Delta\boldsymbol{x}_t$. We use the formula from the algorithm to implement Adadelta.</target>
      </trans-unit>
      <trans-unit id="18">
        <source xml:lang="zh-CN">使用超参数$\rho=0.9$来训练模型。</source>
        <target xml:lang="en-US">Then, we train the model with the hyperparameter $\rho=0.9$.</target>
      </trans-unit>
      <trans-unit id="19">
        <source xml:lang="zh-CN">Gluon实现</source>
        <target xml:lang="en-US">Implementation with Gluon</target>
      </trans-unit>
      <trans-unit id="20">
        <source xml:lang="zh-CN">通过算法名称为“adadelta”的<bpt id="2">`</bpt>Trainer<ept id="2">`</ept>实例，我们便可在Gluon中使用Adadelta算法。它的超参数可以通过<bpt id="4">`</bpt>rho<ept id="4">`</ept>来指定。</source>
        <target xml:lang="en-US">From the <bpt id="2">`</bpt>Trainer<ept id="2">`</ept> instance for the algorithm named "adadelta", we can implement Adadelta in Gluon. Its hyperparameters can be specified by <bpt id="4">`</bpt>rho<ept id="4">`</ept>.</target>
      </trans-unit>
      <trans-unit id="21">
        <source xml:lang="zh-CN">小结</source>
        <target xml:lang="en-US">Summary</target>
      </trans-unit>
      <trans-unit id="22">
        <source xml:lang="zh-CN">Adadelta没有学习率超参数，它通过使用有关自变量更新量平方的指数加权移动平均的项来替代学习率。</source>
        <target xml:lang="en-US">Adadelta has no learning rate hyperparameter, it uses an EWMA on the squares of elements in the variation of the independent variable to replace the learning rate.</target>
      </trans-unit>
      <trans-unit id="23">
        <source xml:lang="zh-CN">练习</source>
        <target xml:lang="en-US">exercise</target>
      </trans-unit>
      <trans-unit id="24">
        <source xml:lang="zh-CN">调节$\rho$的值，观察实验结果。</source>
        <target xml:lang="en-US">Adjust the value of $\rho$ and observe the experimental results.</target>
      </trans-unit>
      <trans-unit id="25">
        <source xml:lang="zh-CN">扫码直达<bpt id="l2">[</bpt>讨论区<ept id="l2">]</ept><bpt id="l3">(</bpt>https://discuss.gluon.ai/t/topic/2277<ept id="l3">)</ept></source>
        <target xml:lang="en-US">Scan the QR Code to Access <bpt id="l2">[</bpt>Discussions<ept id="l2">]</ept><bpt id="l3">(</bpt>https://discuss.gluon.ai/t/topic/2277<ept id="l3">)</ept></target>
      </trans-unit>
      <trans-unit id="26">
        <source xml:lang="zh-CN"><bpt id="1">![</bpt>../img/qr_adadelta.svg<ept id="1">]</ept></source>
        <target xml:lang="en-US"><bpt id="1">![</bpt>../img/qr_adadelta.svg<ept id="1">]</ept></target>
      </trans-unit>
      <trans-unit id="27">
        <source xml:lang="zh-CN">参考文献</source>
        <target xml:lang="en-US">Reference</target>
      </trans-unit>
      <trans-unit id="28">
        <source xml:lang="zh-CN"><bpt id="1">[</bpt>1<ept id="1">]</ept> Zeiler, M.</source>
        <target xml:lang="en-US"><bpt id="1">[</bpt>1<ept id="1">]</ept> Zeiler, M.</target>
      </trans-unit>
      <trans-unit id="29">
        <source xml:lang="zh-CN">D.</source>
        <target xml:lang="en-US">D.</target>
      </trans-unit>
      <trans-unit id="30">
        <source xml:lang="zh-CN">(2012).</source>
        <target xml:lang="en-US">(2012).</target>
      </trans-unit>
      <trans-unit id="31">
        <source xml:lang="zh-CN">ADADELTA: an adaptive learning rate method. arXiv preprint arXiv:1212.5701.</source>
        <target xml:lang="en-US">ADADELTA: an adaptive learning rate method. arXiv preprint arXiv:1212.5701.</target>
      </trans-unit>
    </body>
 </file>
</xliff>